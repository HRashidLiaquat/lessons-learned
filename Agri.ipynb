{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoRx5irMye+iXPuUvU8rS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HRashidLiaquat/lessons-learned/blob/Transformer-based-crop-disease-detection-system/Agri.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Workflow**\n",
        "\n",
        "\n",
        "1.   Import Important Libraries\n",
        "2.   Get Data Ready in Kaggle\n",
        "3.   Preparing data\n",
        "4.   Loading Training Images\n",
        "5.   Data Loaders\n",
        "6.   Build a Traning Model (Transfer Learning)\n",
        "7.   Model Training\n",
        "8.   Model Testing (Training Loop)\n",
        "9.   Model Evaluation\n",
        "10.  Testing with New Data Point\n",
        "11.  Save Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8DVWYDw9wzHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Important libraries**"
      ],
      "metadata": {
        "id": "k0UnFUCn4Z1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import ViTForImageClassification\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "Fa7ThugO4njK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount GDrive**"
      ],
      "metadata": {
        "id": "A_3AU2p8Qt23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3kQaVxY_Qz6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zip to unZip data**"
      ],
      "metadata": {
        "id": "KMo9D2PbRZ--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = Path(\"/content/drive/MyDrive/Colab Notebooks/agriarchive.zip\")\n",
        "extract_path = Path(\"/content/data\")\n",
        "\n",
        "print(\"ZIP exists:\", zip_path.exists())\n",
        "\n",
        "extract_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "PwUMfM3uRdO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get Ready dataset**"
      ],
      "metadata": {
        "id": "9Dly3_abSieY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datset_path = Path('/content/data/PlantVillage')\n",
        "\n",
        "if datset_path.exists():\n",
        "  print(\"Dataset found!\")\n",
        "else:\n",
        "  print(\"Dataset not found!\")"
      ],
      "metadata": {
        "id": "P6BIglO7Sl1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if datset_path.exists():\n",
        "  datsetfolderlist = list(datset_path.iterdir())\n",
        "  print(\"See all folder in my dataset main folder\")\n",
        "  for allfolder in datsetfolderlist:\n",
        "      print(allfolder)"
      ],
      "metadata": {
        "id": "aDf6wTB7TP6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check Total plant classes data**"
      ],
      "metadata": {
        "id": "l0AjdvvmUG31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "traning_path = datset_path / '/content/data/PlantVillage/train'\n",
        "print(traning_path)\n",
        "# test_path = datset_path / '/content/data/PlantVillage/train/val'\n",
        "train_classes = [item.name for item in traning_path.iterdir() if item.is_dir()]\n",
        "train_classes.sort()\n",
        "num_classes = len(train_classes)\n",
        "print(f\"Total plant classes: {num_classes}\")\n",
        "# print(test_path)"
      ],
      "metadata": {
        "id": "X5rUP3CHTea2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Raw data**"
      ],
      "metadata": {
        "id": "TpAISrisUrgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rawdataset = datasets.ImageFolder(traning_path, transform=transforms.ToTensor())\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(8):\n",
        "    idx = random.randint(0, len(rawdataset)-1)\n",
        "    img, label = rawdataset[idx]\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "    plt.title(rawdataset.classes[label])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "o1lB230WU1xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing (Normalization and augmentation)**"
      ],
      "metadata": {
        "id": "D-goKQzCZDEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "jYoaOxNVZ6IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Augmentattion**"
      ],
      "metadata": {
        "id": "bRTnRcUnb3Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(0.2,0.2,0.2)\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "sWKRG5EqcBup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_transforms"
      ],
      "metadata": {
        "id": "Ny0CNeSZf-Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WithOut augmentation**"
      ],
      "metadata": {
        "id": "QjVFhevloRcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ],
      "metadata": {
        "id": "f1pSTwJnoPZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**\n",
        "\n"
      ],
      "metadata": {
        "id": "NAabDeZxddaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prepro_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "m3IBYcbSdjq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepro_transforms"
      ],
      "metadata": {
        "id": "WG33qA8Heqmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Normaliztion**"
      ],
      "metadata": {
        "id": "JE0q41Tjfx9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_transform = transforms.Normalize(\n",
        "    mean = [0.485, 0.456, 0.406],\n",
        "    std=[0.229, 0.224, 0.225]\n",
        ")"
      ],
      "metadata": {
        "id": "bRZZReEEgTuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_transform"
      ],
      "metadata": {
        "id": "755z-UNTiYbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_trasform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "AOodHeMyipkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Show Data after Preprocessing**"
      ],
      "metadata": {
        "id": "Ny9SjoiQmwYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_datase = datasets.ImageFolder(traning_path, transform=transforms.ToTensor())\n",
        "def denorm(x):\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    return torch.clamp(x * std + mean, 0, 1)\n"
      ],
      "metadata": {
        "id": "B0Zksi5XnW1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(8):\n",
        "    idx = random.randint(0, len(processed_datase)-1)\n",
        "    img, label = processed_datase[idx]\n",
        "\n",
        "    img = denorm(img)\n",
        "\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    plt.imshow(img.permute(1, 2, 0))\n",
        "    plt.title(processed_datase.classes[label])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.suptitle('Show After Preprocessing (224x224)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IhRxjy9Dp3o9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "AM7V9JpSfqgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(datset_path, transform=train_trasform)\n",
        "print(\"Total images:\", len(dataset))\n",
        "print(\"Classes:\", dataset.classes)"
      ],
      "metadata": {
        "id": "T3TXmghwfsbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/PlantVillage/train\"\n",
        "val_path   = \"/content/drive/MyDrive/PlantVillage/val\""
      ],
      "metadata": {
        "id": "OeIlYxj7iFR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir ,val_path"
      ],
      "metadata": {
        "id": "viuPFu4WiMLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/data/PlantVillage/train'\n",
        "val_path   = '/content/data/PlantVillage/val'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_trasform)\n",
        "val_dataset   = datasets.ImageFolder(val_path, transform=test_transform)\n",
        "\n",
        "print(\"Total train images:\", len(train_dataset))\n",
        "print(\"Train classes:\", train_dataset.classes)\n",
        "print(\"Total val images:\", len(val_dataset))"
      ],
      "metadata": {
        "id": "nZSmBTywpPoO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}